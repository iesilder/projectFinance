{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zipline기초.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/iesilder/projectFinance/blob/master/Zipline%EA%B8%B0%EC%B4%88.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "bS7K5Af929jg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "19e1bddc-3989-40df-e924-394c2d14fb28"
      },
      "cell_type": "code",
      "source": [
        "# 라이브러리 설치\n",
        "!pip install pandas_datareader"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas_datareader\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/76/639c60ede26458dadf76bacaa9cbcc76f8cc5082fb2b2d90d0a90c699d36/pandas_datareader-0.6.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 2.3MB/s \n",
            "\u001b[?25hCollecting lxml (from pandas_datareader)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/81/5a3e70c8adc20fb295a2f4c9fdf09af8295c7a00ccec6ee3d31084cbf272/lxml-4.2.3-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.9MB 3.3MB/s \n",
            "\u001b[?25hCollecting wrapt (from pandas_datareader)\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (0.22.0)\n",
            "Collecting requests-ftp (from pandas_datareader)\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/ca/14b2ad1e93b5195eeaf56b86b7ecfd5ea2d5754a68d17aeb1e5b9f95b3cf/requests-ftp-0.3.1.tar.gz\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (2.18.4)\n",
            "Collecting requests-file (from pandas_datareader)\n",
            "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2018.5)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (1.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2.5.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2018.4.16)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (1.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from requests-file->pandas_datareader) (1.11.0)\n",
            "Building wheels for collected packages: wrapt, requests-ftp\n",
            "  Running setup.py bdist_wheel for wrapt ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
            "  Running setup.py bdist_wheel for requests-ftp ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/2a/98/32/37195e45a3392a73d9f65c488cbea30fe5bad76aaef4d6b020\n",
            "Successfully built wrapt requests-ftp\n",
            "Installing collected packages: lxml, wrapt, requests-ftp, requests-file, pandas-datareader\n",
            "Successfully installed lxml-4.2.3 pandas-datareader-0.6.0 requests-file-1.4.3 requests-ftp-0.3.1 wrapt-1.10.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FUV2Xx_q3Ldt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 사용할 라이브러리 import\n",
        "import pandas_datareader.data as web\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "23psL4Qv4Qd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# html에 있는 정보를 읽어온다.\n",
        "# 여기서 가져오는 정보는 종목 코드명이다.\n",
        "code_df = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13', header=0)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ux7FmbOq4Y8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5db1c761-e523-4fd4-bc31-bcf074c88147"
      },
      "cell_type": "code",
      "source": [
        "print(type(code_df))\n",
        "print(code_df.head())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "     회사명   종목코드             업종                         주요제품         상장일  결산월  \\\n",
            "0     CJ   1040         기타 금융업                         지주회사  1973-06-29  12월   \n",
            "1    HDC  12630         건물 건설업  토목공사,건축공사,아파트분양사업,재개발/재건축사업  1996-10-16  12월   \n",
            "2  HSD엔진  82740  일반 목적용 기계 제조업               대형선박용엔진,내연발전엔진  2011-01-04  12월   \n",
            "3  KG케미칼   1390    기초 화학물질 제조업    콘크리트혼화제, 비료, 친환경농자재, 수처리제  1989-08-25  12월   \n",
            "4  LG이노텍  11070       전자부품 제조업                  기타 전자부품 제조업  2008-07-24  12월   \n",
            "\n",
            "            대표자명                         홈페이지     지역  \n",
            "0  손경식, 이재현, 이채욱            http://www.cj.net  서울특별시  \n",
            "1            정몽규        http://www.i-park.com  서울특별시  \n",
            "2            고영열  http://www.doosanengine.com   경상남도  \n",
            "3            김경묵      http://www.kgchem.co.kr  울산광역시  \n",
            "4            박종석   http://www.lginnotek.co.kr  서울특별시  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IJPiyrgh5f5D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 종목코드를 균일하게 000000자리로 맞추는 작업을 한다.\n",
        "code_df.종목코드 = code_df.종목코드.map('{:06d}'.format)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iflydy6L50vs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 한글로 된 컬럼명을 영어로 바꾼다.\n",
        "code_df = code_df.rename(columns={'회사명':'name', '종목코드':'code'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7bi9CURV6B-x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# code_df에서 필요한 컬럼만 뽑아서 새로 code_df를 정의한다.\n",
        "code_df = code_df[['name', 'code']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "be4jZ4Ug6fd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 특정 업체의 코드를 가져오기 위한 함수 정의\n",
        "def get_url(item_name, code_df):\n",
        "    # 코드를 가져오기 위한 처리.\n",
        "    # 먼저 .query(\"name=='{}'\".format(item_name))['code']는 name 컬럼에 item_name과 동일한 값의 code값을 반환한다는 뜻.\n",
        "    # 즉, .query(\"쿼리\".format(쿼리에 넣을 데이터))[얻을 자료]\n",
        "    # .to_string(index = False)로 위에서 얻어진 값에 index를 빼고 string타입으로 바꿔준다.\n",
        "    code = code_df.query(\"name=='{}'\".format(item_name))['code'].to_string(index = False)\n",
        "    # url은 일일 종가 시가 고가 저가 거래량을 보여주는 표이다.\n",
        "    url = 'http://finance.naver.com/item/sise_day.nhn?code={code}'.format(code = code)\n",
        "    print(\"요청 URL = {}\".format(url))\n",
        "    return url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NxjxxAT17Hmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "ebbbf813-12f2-475c-824f-8fe8b9662e15"
      },
      "cell_type": "code",
      "source": [
        "# 데이터를 확인해본다.\n",
        "code_df['name'][:20]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          CJ\n",
              "1         HDC\n",
              "2       HSD엔진\n",
              "3       KG케미칼\n",
              "4       LG이노텍\n",
              "5     SH에너지화학\n",
              "6      SK네트웍스\n",
              "7      STX중공업\n",
              "8      WISCOM\n",
              "9     갤럭시아에스엠\n",
              "10     경동도시가스\n",
              "11       고려제강\n",
              "12    골든브릿지증권\n",
              "13       극동유화\n",
              "14     금호에이치티\n",
              "15      까뮤이앤씨\n",
              "16      노루페인트\n",
              "17     녹십자홀딩스\n",
              "18      대덕GDS\n",
              "19     대림씨엔에스\n",
              "Name: name, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "E2oSRO2i8y5W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# code_df.name에서 \"LG\"가 들어간 데이터만 추출한다.\n",
        "lg_list = []\n",
        "for i in range(len(code_df['name'])):\n",
        "  if \"LG\" in code_df['name'][i]:\n",
        "    lg_list.append(code_df.loc[i].tolist())\n",
        "# list = code_df.loc[code_df['name'].str.contains(\"LG\")]  # 이렇게 해도 추출된다. 이후 처리 필요."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12wVvqcm-qu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 추출한 데이터를 데이터프레임으로 바꾼다.\n",
        "lg_df = pd.DataFrame(lg_list, columns=['name', 'code'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tb7CdsFaCLxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "cdb00c54-84e2-4cbb-bab6-cbdf3f5242da"
      },
      "cell_type": "code",
      "source": [
        "# 데이터 확인\n",
        "lg_df"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LG이노텍</td>\n",
              "      <td>011070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LG디스플레이</td>\n",
              "      <td>034220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LG하우시스</td>\n",
              "      <td>108670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LG</td>\n",
              "      <td>003550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LG유플러스</td>\n",
              "      <td>032640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LG전자</td>\n",
              "      <td>066570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LG화학</td>\n",
              "      <td>051910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LG상사</td>\n",
              "      <td>001120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LG생활건강</td>\n",
              "      <td>051900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      name    code\n",
              "0    LG이노텍  011070\n",
              "1  LG디스플레이  034220\n",
              "2   LG하우시스  108670\n",
              "3       LG  003550\n",
              "4   LG유플러스  032640\n",
              "5     LG전자  066570\n",
              "6     LG화학  051910\n",
              "7     LG상사  001120\n",
              "8   LG생활건강  051900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "metadata": {
        "id": "Oh9wupyMNKqb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 각 회사별 자료를 사전 타입에 저장을 한다.\n",
        "# 2016~2017 자료를 train, 2018-01-01~2018-07-27까지의 자료를 test로 놓겠다.\n",
        "lg_dict_train = {}  # 저장할 객체\n",
        "lg_dict_test = {}\n",
        "name_list = lg_df.name  # 이름\n",
        "code_list = lg_df.code  # 코드\n",
        "url = 'http://finance.naver.com/item/sise_day.nhn?code='\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gSf9xmGoROr8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 페이지 자료에 맞춰서 데이터를 구분한다.\n",
        "# test 데이터\n",
        "for i in range(len(lg_df.name)):\n",
        "    for page in range(1, 15):  # 1~14페이지까지 2018-01-01~2018-07-27 자료\n",
        "        if page == 1:\n",
        "            df = pd.DataFrame()\n",
        "        pg_url = url + '{code}&page={page}'.format(code = code_list[i], \n",
        "                                                   page = page)  # url을 저장한다.\n",
        "        # 데이터 프레임으로 만든다.\n",
        "        df = df.append(pd.read_html(pg_url, header = 0)[0], ignore_index = True)\n",
        "        if page == 14:  # 전처리 및 저장을 한다.\n",
        "            df = df.rename(columns= {'날짜': 'date', '종가': 'close', \n",
        "             '전일비': 'diff', '시가': 'open', '고가': 'high', \n",
        "             '저가': 'low', '거래량': 'volume'})  # 컬럼명을 바꾼다.\n",
        "            # 결측치 제거 및 오름차순으로 정렬한다.\n",
        "            df = df.sort_values('date', ascending=True).dropna()\n",
        "            lg_dict_test[name_list[i]] = df  # 데이터프레임을 key, value로 저장한다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wEEVh-6KSeOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1143
        },
        "outputId": "0542f5d3-a27b-4688-ffb6-27593a649944"
      },
      "cell_type": "code",
      "source": [
        "print(lg_dict_test[name_list[0]])  # 데이터 확인"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           date     close     diff      open      high       low     volume\n",
            "208  2018.01.03  147000.0   2000.0  146000.0  148000.0  143500.0   254861.0\n",
            "207  2018.01.04  145000.0   2000.0  148000.0  148500.0  144500.0   186790.0\n",
            "206  2018.01.05  145500.0    500.0  146000.0  148000.0  143000.0   236799.0\n",
            "205  2018.01.08  142000.0   3500.0  148000.0  148500.0  139500.0   471519.0\n",
            "204  2018.01.09  156500.0  14500.0  153500.0  160500.0  149000.0  1239506.0\n",
            "200  2018.01.10  149000.0   7500.0  157000.0  157500.0  147500.0   603263.0\n",
            "199  2018.01.11  150500.0   1500.0  149500.0  150500.0  147000.0   349462.0\n",
            "198  2018.01.12  146000.0   4500.0  149500.0  150000.0  142000.0   524718.0\n",
            "197  2018.01.15  144500.0   1500.0  145000.0  146000.0  143000.0   140423.0\n",
            "196  2018.01.16  146000.0   1500.0  143000.0  147500.0  141000.0   318389.0\n",
            "193  2018.01.17  143000.0   3000.0  144500.0  147500.0  141500.0   367226.0\n",
            "192  2018.01.18  140000.0   3000.0  144500.0  145000.0  139500.0   411860.0\n",
            "191  2018.01.19  132500.0   7500.0  140000.0  140500.0  131000.0  1096410.0\n",
            "190  2018.01.22  129000.0   3500.0  128500.0  130000.0  126000.0   600558.0\n",
            "189  2018.01.23  130500.0   1500.0  129000.0  132500.0  126500.0   601325.0\n",
            "185  2018.01.24  127000.0   3500.0  127000.0  129500.0  126500.0   699480.0\n",
            "184  2018.01.25  126500.0    500.0  125000.0  127000.0  123000.0   642862.0\n",
            "183  2018.01.26  127000.0    500.0  126500.0  129000.0  126000.0   412126.0\n",
            "182  2018.01.29  130500.0   3500.0  128000.0  132000.0  127500.0   484915.0\n",
            "181  2018.01.30  129500.0   1000.0  130500.0  133500.0  129500.0   469144.0\n",
            "178  2018.01.31  125500.0   4000.0  128000.0  129500.0  125500.0   442839.0\n",
            "177  2018.02.01  128500.0   3000.0  126000.0  131000.0  125000.0   487650.0\n",
            "176  2018.02.02  127500.0   1000.0  131000.0  132500.0  126000.0   463775.0\n",
            "175  2018.02.05  123500.0   4000.0  124000.0  126000.0  123000.0   247412.0\n",
            "174  2018.02.06  122500.0   1000.0  118000.0  123000.0  117500.0   397169.0\n",
            "170  2018.02.07  121000.0   1500.0  125500.0  126500.0  121000.0   302792.0\n",
            "169  2018.02.08  126500.0   5500.0  121500.0  126500.0  121500.0   249516.0\n",
            "168  2018.02.09  123000.0   3500.0  122500.0  124000.0  120500.0   184381.0\n",
            "167  2018.02.12  124500.0   1500.0  125000.0  126000.0  122500.0   162742.0\n",
            "166  2018.02.13  122000.0   2500.0  126000.0  128000.0  122000.0   260878.0\n",
            "..          ...       ...      ...       ...       ...       ...        ...\n",
            "43   2018.06.18  148500.0   5000.0  154000.0  154500.0  145000.0   364123.0\n",
            "42   2018.06.19  141500.0   7000.0  147500.0  149000.0  141500.0   273473.0\n",
            "41   2018.06.20  146500.0   5000.0  142000.0  148000.0  141500.0   177191.0\n",
            "40   2018.06.21  146000.0    500.0  146000.0  149000.0  145000.0   157257.0\n",
            "39   2018.06.22  139000.0   7000.0  144000.0  145500.0  137000.0   439214.0\n",
            "35   2018.06.25  145000.0   6000.0  138500.0  145000.0  135500.0   220431.0\n",
            "34   2018.06.26  141000.0   4000.0  141500.0  145000.0  139500.0   160745.0\n",
            "33   2018.06.27  140000.0   1000.0  140500.0  144000.0  139500.0   112186.0\n",
            "32   2018.06.28  140500.0    500.0  140500.0  141000.0  138000.0   121640.0\n",
            "31   2018.06.29  144500.0   4000.0  140500.0  145000.0  140000.0   160170.0\n",
            "28   2018.07.02  142000.0   2500.0  145000.0  146500.0  141000.0   113375.0\n",
            "27   2018.07.03  140500.0   1500.0  143500.0  143500.0  136000.0   109609.0\n",
            "26   2018.07.04  139500.0   1000.0  138000.0  142000.0  137000.0    81232.0\n",
            "25   2018.07.05  145500.0   6000.0  142000.0  150000.0  142000.0   363258.0\n",
            "24   2018.07.06  156000.0  10500.0  147500.0  156000.0  147500.0   564528.0\n",
            "20   2018.07.09  160500.0   4500.0  156500.0  161000.0  156000.0   325136.0\n",
            "19   2018.07.10  157500.0   3000.0  159000.0  160500.0  155500.0   107907.0\n",
            "18   2018.07.11  156000.0   1500.0  156500.0  159500.0  153500.0   132688.0\n",
            "17   2018.07.12  158500.0   2500.0  158000.0  161000.0  156000.0   218557.0\n",
            "16   2018.07.13  160000.0   1500.0  158000.0  163500.0  157000.0   168005.0\n",
            "13   2018.07.16  162000.0   2000.0  160000.0  163500.0  160000.0    96050.0\n",
            "12   2018.07.17  158000.0   4000.0  163000.0  163500.0  157000.0   121429.0\n",
            "11   2018.07.18  160000.0   2000.0  160000.0  162500.0  159000.0   125858.0\n",
            "10   2018.07.19  158000.0   2000.0  161000.0  161500.0  156500.0    94944.0\n",
            "9    2018.07.20  158500.0    500.0  159000.0  160500.0  156500.0   124904.0\n",
            "5    2018.07.23  155000.0   3500.0  157000.0  158500.0  150500.0   234183.0\n",
            "4    2018.07.24  161000.0   6000.0  155500.0  161500.0  155500.0   142988.0\n",
            "3    2018.07.25  162500.0   1500.0  163000.0  163000.0  160000.0   170304.0\n",
            "2    2018.07.26  158500.0   4000.0  163500.0  166500.0  157000.0   288066.0\n",
            "1    2018.07.27  160500.0   2000.0  159500.0  161500.0  157500.0   115752.0\n",
            "\n",
            "[140 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9BShQhe_W8Hv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 페이지 자료에 맞춰서 데이터를 구분한다.\n",
        "# train 데이터\n",
        "for i in range(len(lg_df.name)):\n",
        "    for page in range(15, 64):  # 15~64페이지까지 2016~2017 자료\n",
        "        if page == 1:\n",
        "            df = pd.DataFrame()\n",
        "        pg_url = url + '{code}&page={page}'.format(code = code_list[i], \n",
        "                                                   page = page)  # url을 저장한다.\n",
        "        # 데이터 프레임으로 만든다.\n",
        "        df = df.append(pd.read_html(pg_url, header = 0)[0], ignore_index = True)\n",
        "        if page == 14:  # 전처리 및 저장을 한다.\n",
        "            df = df.rename(columns= {'날짜': 'date', '종가': 'close', \n",
        "             '전일비': 'diff', '시가': 'open', '고가': 'high', \n",
        "             '저가': 'low', '거래량': 'volume'})  # 컬럼명을 바꾼다.\n",
        "            # 결측치 제거 및 오름차순으로 정렬한다.\n",
        "            df = df.sort_values('date', ascending=True).dropna()\n",
        "            lg_dict_test[name_list[i]] = df  # 데이터프레임을 key, value로 저장한다."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}